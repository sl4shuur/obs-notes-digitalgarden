---
{"dg-publish":true,"dg-path":"KSE/Optimization Techniques/03. Convex Functions.md","permalink":"/kse/optimization-techniques/03-convex-functions/","tags":["kse","math/calculus"],"created":"2025-02-17T14:43:43.797+02:00","updated":"2025-03-09T14:43:45.301+02:00"}
---

# Convex Functions

---

Weve learned that **[[02 - KSE/2_5-term/Methods of Optimization/02. Convex Sets\|convex sets]]** create smooth, well-behaved landscapes for optimization. Now, lets explore the **functions** that live on these landscapes: **convex functions**. These functions are the heart of many optimization techniques because they guarantee **no traps, no false minima, and a single, clear path to the best solution.**

---

## What Is a Convex Function?

A function is **convex** if its graph curves **upward**like a **bowl**. The key property of a convex function is that the line segment between any two points on the graph lies **above or on the graph itself**.

<strong><span style="color: var(--color-red);">Formally:</span></strong>
A function $f: \mathbb{R}^n \to \mathbb{R}$ is **convex** if:

1. The domain $D(f)$ is a **convex set**.
2. For all $\mathbf{x}, \mathbf{y} \in D(f)$ and $\lambda \in [0,1]$, the **function satisfies**:

$$
f(\lambda \mathbf{x} + (1 - \lambda) \mathbf{y})
\leq
\lambda f(\mathbf{x}) + (1 - \lambda) f(\mathbf{y})
$$

This means that for any two points $\mathbf{x}$ and $\mathbf{y}$, the function value at any weighted average of these points is **at most** the weighted average of the function values. In other words, the function <strong><span style="color: var(--color-cyan);">does not "dip"</span></strong> between two points.

### Strictly Convex Functions

A function is **strictly convex** if the inequality is strict for all distinct $\mathbf{x} \neq \mathbf{y}$:

$$
f(\lambda \mathbf{x} + (1 - \lambda) \mathbf{y}) < \lambda f(\mathbf{x}) + (1 - \lambda) f(\mathbf{y}) \quad \text{for all } \mathbf{x}, \mathbf{y} \text{ and } \lambda \in (0,1)
$$

Strict convexity ensures <strong><span style="color: var(--color-aqua);">uniqueness</span></strong> of the minimumthere is only **ONE** lowest point.

Let's compare the formal definitions of convex and strictly convex functions:

- **Convex function:**

  $$
  f(\lambda \mathbf{x} + (1 - \lambda) \mathbf{y}) \textcolor{var(--color-cyan)}{\leq} \lambda f(\mathbf{x}) + (1 - \lambda) f(\mathbf{y}) \quad \text{for all } \mathbf{x}, \mathbf{y} \text{ and } \lambda \in \textcolor{var(--color-cyan)}{[} 0,1 \textcolor{var(--color-cyan)}{]}
  $$

- **Strictly convex function:**
  $$
  f(\lambda \mathbf{x} + (1 - \lambda) \mathbf{y}) \textcolor{var(--color-red)}{<} \lambda f(\mathbf{x}) + (1 - \lambda) f(\mathbf{y}) \quad \text{for all } \mathbf{x}, \mathbf{y} \text{ and } \lambda \in \textcolor{var(--color-red)}{(} 0,1 \textcolor{var(--color-red)}{)}
  $$

So we can observe that **strict convexity** is a <strong><span style="color: var(--color-red);">stronger condition</span></strong> than <strong><span style="color: var(--color-cyan);">convexity</span></strong>.

![Strict convex.png](/img/user/assets/Strict%20convex.png)

## Geometric Interpretation

- **Convex function:** The line segment between any two points lies above or on the function.
- **Strictly convex function:** The line segment is always strictly above the function.

This guarantees that there are **no multiple minima**, which is a key reason why convex functions are fundamental in optimization.

<svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 700.2617084577619 360.5691405593575" width="700.2617084577619" height="360.5691405593575" class="excalidraw-svg"><!-- svg-source:excalidraw --><metadata></metadata><defs><style class="style-fonts">      @font-face { font-family: Excalifont; src: url(data:font/woff2;base64,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); }      @font-face { font-family: Excalifont; src: url(data:font/woff2;base64,d09GMgABAAAAAAJ0AA0AAAAABKQAAAIiAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGx4cNAZgADQRCAqBFIEUCwYAATYCJAMIBCAFgxgHIBu7A8geB7nZ6B6YMJFA4bTBw1tX/aQygLNSv94RvSJOAk57hs6QC5lwC4ADDC4vzmXLHWeRHEmU6i9JMI/CX0SBpoG+2HPktYBaYJpuLmmeQRbENM4wXhEBOBIsmMjMLqzEHgVgmgAIwJFw4ZTYHbpp40cSeOMHjSDw2yaOJhDwLitZKdZig71cLmuBAvaIZsL9Bn+uIrM5xdwwLkea/H85m1YRkzVsB4jFshbQ7AEJGIA3A0FZoYFCIcC4bJr9OX+zEQCAME0kABIABQjAAuIAgAIAhKXmYc2u6k3HfPd1X35os9h03un87fshJ+8H3E87mnjgZt9DDx5Ub7xx4MQJf6v4Q7t6t0Stnz9/RkiL/Y2nWSsCD/mp6A/RreeC06dEx1/ZZdDdHT7S4tCkCz3T/BqyIxxvtW8590mviwYAAQh4dnrYsRa3xG/2TsZLgEfT+mYCPN71Zoa58P8M9VrFAfZIAAR8KNp4Cvvvb4sAzJRGO1l5QhABSB5iC4AEBAJIBQBgRz0DoRyAke4MBN6uQeLKCRj0tRiK7tphQ7LuZJvakGWqDm1GGmawMUabaIBygwwxyUhtxqs2yHgTDFO5NpCFtV6cIMdI04w11ARaBItwWm8RwoWL0efcofnZeKYKOYolWDzrkjJ461jTjDfMEENNpPXWoQ8tnFW4SFq7abS7stN4baaw0NKMNJL2w4RFg2gGHTXZIJ0sDAAw/2MDAAAAAA==); }</style></defs><rect x="0" y="0" width="700.2617084577619" height="360.5691405593575" fill="#ffffff"></rect><g stroke-linecap="round"><g transform="translate(74.7382947828728 96.45359281626895) rotate(0 261.29778849592 58.49166302839954)"><path d="M-0.66 0.66 C14.46 21.28, 58.11 92.72, 90.09 122.61 C122.07 152.51, 155.16 170.53, 191.24 180.01 C227.32 189.5, 272.36 185.75, 306.58 179.52 C340.79 173.3, 369.02 161.18, 396.55 142.66 C424.08 124.14, 450.67 102.55, 471.75 68.4 C492.83 34.25, 514.58 -40.29, 523.03 -62.25 M1.19 -0.04 C16.28 20.3, 57.96 91.02, 89.59 120.68 C121.22 150.34, 154.77 167.92, 190.98 177.94 C227.18 187.96, 272.26 186.57, 306.82 180.8 C341.38 175.03, 371.14 162.15, 398.32 143.32 C425.5 124.48, 448.96 102.27, 469.89 67.81 C490.82 33.35, 515.33 -41.46, 523.91 -63.45" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g></g><mask></mask><g stroke-linecap="round"><g transform="translate(130.56933191230536 179.91980863315064) rotate(0 218.50781134734288 16.806651451105196)"><path d="M-0.26 -0.3 C8.37 8.64, 27.91 37.16, 50.79 53.13 C73.68 69.1, 103.08 88.36, 137.06 95.53 C171.03 102.7, 220.25 102.33, 254.64 96.16 C289.03 90, 317.89 75, 343.41 58.53 C368.93 42.05, 392.07 17.77, 407.74 -2.68 C423.41 -23.13, 432.5 -53.97, 437.42 -64.19 M1.81 -1.5 C10.92 7.61, 30.8 37.92, 53.16 54.24 C75.53 70.56, 102.31 89.29, 136 96.42 C169.68 103.55, 220.89 103.2, 255.26 97.01 C289.64 90.83, 317.18 76.14, 342.25 59.33 C367.31 42.52, 389.67 16.45, 405.67 -3.86 C421.68 -24.16, 433.16 -52.32, 438.28 -62.48" stroke="#4dabf7" stroke-width="4" fill="none"></path></g></g><mask></mask><g transform="translate(33 168.36912937411248) rotate(0 40.219970703125 12.5)"><text x="0" y="17.619999999999997" font-family="Excalifont, Xiaolai, Segoe UI Emoji" font-size="20px" fill="#1e1e1e" text-anchor="start" style="white-space: pre;" direction="ltr" dominant-baseline="alphabetic">(x, f(x))</text></g><g transform="translate(589.2617694929181 95.8432753649333) rotate(0 38.999969482421875 12.5)"><text x="0" y="17.619999999999997" font-family="Excalifont, Xiaolai, Segoe UI Emoji" font-size="20px" fill="#1e1e1e" text-anchor="start" style="white-space: pre;" direction="ltr" dominant-baseline="alphabetic">(y, f(y))</text></g><g stroke-linecap="round"><g transform="translate(129.21816495456972 177.78574682932728) rotate(0 221.5573622497052 -32.23477121988702)"><path d="M1.04 -0.58 C75.03 -11.36, 370.1 -52.83, 443.62 -63.64" stroke="#fa5252" stroke-width="2.5" fill="none" stroke-dasharray="8 10"></path></g></g><mask></mask><g transform="translate(129.1637956681284 177.41835910617831) rotate(0 -0.24620841505158353 0.24618963198668098)" stroke="none"><path fill="#1e1e1e" d="M 3.48,-2.92 Q 3.48,-2.92 3.91,-2.32 4.34,-1.73 4.56,-1.03 4.77,-0.32 4.75,0.40 4.73,1.13 4.48,1.82 4.22,2.51 3.77,3.08 3.31,3.65 2.69,4.05 2.07,4.44 1.36,4.62 0.65,4.80 -0.08,4.74 -0.81,4.68 -1.48,4.39 -2.15,4.10 -2.70,3.61 -3.25,3.12 -3.61,2.48 -3.97,1.84 -4.11,1.12 -4.24,0.40 -4.14,-0.32 -4.05,-1.04 -3.72,-1.70 -3.39,-2.36 -2.88,-2.88 -2.36,-3.39 -1.70,-3.72 -1.04,-4.05 -0.32,-4.15 0.40,-4.24 1.12,-4.11 1.84,-3.97 2.48,-3.61 3.12,-3.24 3.61,-2.70 4.10,-2.15 4.39,-1.48 4.68,-0.81 4.74,-0.07 4.80,0.65 4.62,1.36 4.44,2.07 4.05,2.69 3.65,3.31 3.08,3.77 2.51,4.23 1.82,4.48 1.13,4.73 0.40,4.75 -0.33,4.77 -1.03,4.55 -1.73,4.34 -2.32,3.91 -2.92,3.48 -2.92,3.48 -2.92,3.48 -3.29,3.08 -3.67,2.68 -3.94,2.20 -4.20,1.73 -4.35,1.20 -4.50,0.67 -4.51,0.12 -4.53,-0.42 -4.41,-0.95 -4.29,-1.49 -4.05,-1.98 -3.81,-2.48 -3.46,-2.90 -3.11,-3.32 -2.66,-3.64 -2.22,-3.97 -1.71,-4.17 -1.21,-4.38 -0.66,-4.46 -0.12,-4.54 0.42,-4.49 0.96,-4.44 1.48,-4.26 2.00,-4.08 2.46,-3.78 2.92,-3.48 3.20,-3.20 L 3.48,-2.92 Z"></path></g><g transform="translate(569.1799129671983 114.36130714869793) rotate(0 0.00005000000000165983 0.00005000000000165983)" stroke="none"><path fill="#1e1e1e" d="M 3.14,-3.14 Q 3.14,-3.14 3.55,-2.55 3.97,-1.97 4.18,-1.28 4.40,-0.59 4.38,0.11 4.36,0.83 4.11,1.51 3.86,2.18 3.41,2.74 2.96,3.30 2.36,3.69 1.75,4.07 1.05,4.25 0.36,4.42 -0.35,4.36 -1.07,4.30 -1.73,4.02 -2.39,3.74 -2.92,3.26 -3.46,2.78 -3.81,2.15 -4.16,1.53 -4.30,0.82 -4.43,0.11 -4.34,-0.59 -4.24,-1.30 -3.92,-1.94 -3.60,-2.59 -3.09,-3.09 -2.59,-3.60 -1.94,-3.92 -1.30,-4.24 -0.59,-4.34 0.12,-4.43 0.82,-4.30 1.53,-4.16 2.15,-3.81 2.78,-3.46 3.26,-2.92 3.74,-2.39 4.02,-1.73 4.31,-1.07 4.36,-0.35 4.42,0.36 4.25,1.05 4.07,1.75 3.69,2.36 3.30,2.96 2.74,3.41 2.18,3.86 1.51,4.11 0.83,4.36 0.11,4.38 -0.60,4.40 -1.28,4.18 -1.97,3.97 -2.55,3.55 -3.14,3.13 -3.14,3.14 -3.14,3.14 -3.47,2.71 -3.80,2.29 -4.02,1.80 -4.24,1.32 -4.33,0.79 -4.43,0.26 -4.40,-0.26 -4.36,-0.80 -4.20,-1.31 -4.04,-1.82 -3.77,-2.28 -3.49,-2.73 -3.11,-3.11 -2.73,-3.49 -2.28,-3.77 -1.82,-4.05 -1.31,-4.20 -0.80,-4.36 -0.26,-4.40 0.26,-4.43 0.79,-4.33 1.32,-4.24 1.80,-4.02 2.29,-3.80 2.71,-3.47 3.14,-3.14 3.14,-3.14 L 3.14,-3.14 Z"></path></g><g transform="translate(308.24452142645987 298.18620962017513) rotate(356.1118007343609 65.05995178222656 12.5)"><text x="0" y="17.619999999999997" font-family="Excalifont, Xiaolai, Segoe UI Emoji" font-size="20px" fill="#4dabf7" text-anchor="start" style="white-space: pre;" direction="ltr" dominant-baseline="alphabetic">f(位x + (1-位)y)</text></g><g transform="translate(283.3027031190588 102.98711182366864) rotate(353.9786907157897 77.97993469238281 12.5)"><text x="0" y="17.619999999999997" font-family="Excalifont, Xiaolai, Segoe UI Emoji" font-size="20px" fill="#fa5252" text-anchor="start" style="white-space: pre;" direction="ltr" dominant-baseline="alphabetic">位f(x) + (1-位)f(y)</text></g></svg>
*this also called sometimes as* <strong><span style="color: var(--color-red);">chord rule</span></strong>. 
The <strong><span style="color: var(--color-red);">red dotted line</span></strong> is the *chord* between two points on the graph and it lies above the <strong><span style="color: var(--color-cyan);">blue part</span></strong> of the graph.

## Examples of Convex Functions

- **Linear functions:** $f(x) = a^T x$
- **Affine functions:** $f(x) = a^T x + b$
- **Quadratic functions** (if $a > 0$): $f(x) = ax^2 + bx + c$
- **Exponential functions:** $f(x) = e^{\alpha x}$
- **Norm functions:** $f(x) = \|x\|$

![Figure 3.2 - Examples of multivariate convex functions.png](/img/user/assets/Figure%203.2%20-%20Examples%20of%20multivariate%20convex%20functions.png)
*Examples of multivariate convex functions*

Understanding convex functions is crucial for solving complex optimization problems efficiently! 

---

## Continuity of convex functions

A convex function is **automatically continuous** if its domain is open:

**Theorem:** If $f$ is convex and its domain $D(f)$ is open, then $f$ is continuous.

<strong><span style="color: var(--color-aqua);">Why is this true?</span></strong>

- Convex functions have no sudden jumps or breaks because their "bowl-shaped" graph must stay smooth to satisfy the chord rule.

---

## How to check if a function is convex using derivatives

### First-order condition (gradient test)

If $f$ is differentiable, it is convex if and only if:

$$
f(y) \geq f(x) + \nabla f(x)^T (y - x) \quad \text{for all } x,y
$$

![Figure 3.3.png|600](/img/user/assets/Figure%203.3.png)

<strong><span style="color: var(--color-aqua);">What does this mean?</span></strong>

- The <strong><span style="color: var(--color-red);">tangent line</span></strong> at any point **is always below** the curve.
- Convex functions never "dip" under their tangents.

---

### Second-order condition (Hessian test)

If $f$ is twice differentiable, it is convex if and only if its **[[02 - KSE/2_5-term/Methods of Optimization/Hessian matrix\|Hessian matrix]]** (second derivative) is **positive semidefinite**:

$$
\nabla^2 f(x) \succeq 0 \quad \text{for all } x
$$

<strong><span style="color: var(--color-aqua);">Explanation:</span></strong>

- The Hessian matrix measures **curvature**.
- Positive semidefinite means the function curves upward everywhere (like a bowl).

So, according to this test, a function $f$ should has **nonnegative second derivative** (curvature) everywhere!

![Bad curvature.png|600](/img/user/assets/Bad%20curvature.png)
_this function is NOT a convex!_ We need only "+"

---

## What's next?

> [!QUESTION] What's next step of the operation?
> After understanding the concept of convex functions, we can move on to exploring new things like:
>
> - [[02 - KSE/2_5-term/Methods of Optimization/04. Epigraph. Jensens Inequality\|Epigraph of a function, Jensen's inequality]], and the [[02 - KSE/2_5-term/Methods of Optimization/Hessian matrix\|Hessian matrix]].
> - [[02 - KSE/2_5-term/Methods of Optimization/05. Convex Optimization\|Convex optimization problems]] and how to solve them efficiently.
